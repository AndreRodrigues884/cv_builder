"""
üéØ CV Builder - Dataset Generator
Gera datasets completos para melhoria de CVs com IA

Uso:
    python scripts/generate_datasets.py
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import List, Dict

class CVDatasetGenerator:
    def __init__(self):
        self.output_dir = Path("datasets/processed")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def generate_text_improvement_dataset(self) -> List[Dict]:
        """Gera dataset para melhoria de texto"""
        print("üìù Gerando dataset de melhoria de texto...")
        
        dataset = []
        
        # ========== EXPERI√äNCIAS PROFISSIONAIS ==========
        experiences = [
            {
                "id": "exp_001",
                "original": "Trabalhei como desenvolvedor na empresa X",
                "section": "experience",
                "improved": "Desenvolvi e mantive aplica√ß√µes web full-stack utilizando React e Node.js, resultando em aumento de 30% na efici√™ncia operacional e redu√ß√£o de 25% no tempo de resposta",
                "improvements": ["verbo de a√ß√£o forte", "tecnologias espec√≠ficas", "quantifica√ß√£o de resultados", "impacto mensur√°vel"],
                "keywords": ["desenvolvi", "mantive", "React", "Node.js", "30%", "25%", "full-stack"],
                "ats_score": 88,
                "industry": "technology",
                "seniority": "mid-level"
            },
            {
                "id": "exp_002",
                "original": "Fiz gest√£o de projetos na empresa",
                "section": "experience",
                "improved": "Geri portfolio de 15 projetos simult√¢neos com or√ßamento total de ‚Ç¨500K, entregando 95% dentro do prazo estabelecido e 20% abaixo do or√ßamento previsto",
                "improvements": ["quantifica√ß√£o clara", "m√©tricas financeiras", "taxa de sucesso", "gest√£o de recursos"],
                "keywords": ["geri", "15 projetos", "‚Ç¨500K", "95%", "20%", "portfolio"],
                "ats_score": 92,
                "industry": "project_management",
                "seniority": "senior"
            },
            {
                "id": "exp_003",
                "original": "Ajudei a equipa com v√°rias tarefas",
                "section": "experience",
                "improved": "Colaborei com equipa cross-functional de 12 pessoas na implementa√ß√£o da metodologia Agile/Scrum, reduzindo time-to-market em 40% e aumentando satisfa√ß√£o do cliente para 4.8/5",
                "improvements": ["especificidade", "tamanho da equipa", "metodologia clara", "impacto medido"],
                "keywords": ["colaborei", "cross-functional", "12 pessoas", "Agile", "Scrum", "40%", "4.8/5"],
                "ats_score": 90,
                "industry": "technology",
                "seniority": "mid-level"
            },
            {
                "id": "exp_004",
                "original": "Trabalhei em marketing digital",
                "section": "experience",
                "improved": "Executei campanhas de marketing digital multi-canal em Google Ads, Meta Ads e LinkedIn, gerando 150K+ impress√µes, 12K leads qualificados e ROI de 320%",
                "improvements": ["plataformas espec√≠ficas", "m√©tricas de performance", "ROI claro", "volume de resultados"],
                "keywords": ["executei", "Google Ads", "Meta Ads", "LinkedIn", "150K+", "12K leads", "320%"],
                "ats_score": 94,
                "industry": "marketing",
                "seniority": "mid-level"
            },
            {
                "id": "exp_005",
                "original": "Dei suporte t√©cnico aos clientes",
                "section": "experience",
                "improved": "Prestei suporte t√©cnico de n√≠vel 2 a 200+ clientes mensais via Zendesk e Slack, mantendo NPS de 87, CSAT de 4.6/5 e reduzindo tempo m√©dio de resolu√ß√£o em 35%",
                "improvements": ["n√≠vel de suporte", "volume quantificado", "m√©tricas de satisfa√ß√£o", "ferramentas usadas"],
                "keywords": ["prestei", "n√≠vel 2", "200+", "Zendesk", "Slack", "NPS 87", "CSAT 4.6", "35%"],
                "ats_score": 86,
                "industry": "customer_support",
                "seniority": "junior"
            }
        ]
        
        # ========== SUM√ÅRIOS PROFISSIONAIS ==========
        summaries = [
            {
                "id": "sum_001",
                "original": "Sou dedicado e gosto de trabalhar em equipa",
                "section": "summary",
                "improved": "Engenheiro de Software com 5+ anos de experi√™ncia em desenvolvimento full-stack (React, Node.js, Python), especializado em arquiteturas cloud-native e microservices. Hist√≥rico comprovado de entrega de solu√ß√µes escal√°veis que aumentaram efici√™ncia operacional em 40% e geraram ‚Ç¨2M+ em valor de neg√≥cio",
                "improvements": ["t√≠tulo profissional claro", "anos de experi√™ncia", "stack tecnol√≥gico", "resultados de neg√≥cio"],
                "keywords": ["5+ anos", "full-stack", "React", "Node.js", "Python", "cloud-native", "40%", "‚Ç¨2M+"],
                "ats_score": 91,
                "industry": "technology",
                "seniority": "mid-level"
            },
            {
                "id": "sum_002",
                "original": "Tenho experi√™ncia em v√°rias √°reas",
                "section": "summary",
                "improved": "Product Manager com 7 anos gerindo roadmaps de produtos SaaS B2B em fintechs e healthtechs. Track record de 5 lan√ßamentos bem-sucedidos que alcan√ßaram 50K+ utilizadores, ‚Ç¨3M ARR e 15% market share. Certificado PSPO III e PSM II pela Scrum.org",
                "improvements": ["role espec√≠fico", "tipo de produto", "ind√∫strias", "certifica√ß√µes"],
                "keywords": ["Product Manager", "7 anos", "SaaS B2B", "50K+", "‚Ç¨3M ARR", "PSPO III", "PSM II"],
                "ats_score": 95,
                "industry": "product_management",
                "seniority": "senior"
            }
        ]
        
        # ========== EDUCA√á√ÉO ==========
        education = [
            {
                "id": "edu_001",
                "original": "Licenciatura em Inform√°tica",
                "section": "education",
                "improved": "Licenciatura em Engenharia Inform√°tica - Universidade do Minho (2018-2021) | M√©dia: 16/20 | Projeto Final: Sistema de Gest√£o de CVs com IA (classifica√ß√£o: 18/20)",
                "improvements": ["nome completo do curso", "institui√ß√£o", "per√≠odo", "m√©dia", "projeto relevante"],
                "keywords": ["Engenharia Inform√°tica", "Universidade do Minho", "16/20", "IA", "18/20"],
                "ats_score": 85
            }
        ]
        
        # ========== SKILLS ==========
        skills = [
            {
                "id": "ski_001",
                "original": "Python, Excel",
                "section": "skills",
                "improved": "Python (NumPy, Pandas, Scikit-learn) | Excel Avan√ßado (Power Query, VBA, Macros) | SQL (PostgreSQL, MySQL) | Git/GitHub",
                "improvements": ["bibliotecas espec√≠ficas", "n√≠vel avan√ßado", "ferramentas relacionadas"],
                "keywords": ["Python", "NumPy", "Pandas", "Excel Avan√ßado", "SQL", "PostgreSQL", "Git"],
                "ats_score": 87
            }
        ]
        
        # Combinar tudo
        dataset.extend(experiences)
        dataset.extend(summaries)
        dataset.extend(education)
        dataset.extend(skills)
        
        # Adicionar metadata
        for item in dataset:
            item['created_at'] = datetime.now().isoformat()
            item['language'] = 'pt-PT'
        
        return dataset
    
    def generate_skills_database(self) -> Dict:
        """Gera base de dados completa de skills por √°rea"""
        print("üí° Gerando database de skills...")
        
        database = {
            "technology": {
                "frontend": [
                    {"name": "React", "priority": "high", "demand_score": 95, "salary_impact": "+18%"},
                    {"name": "Vue.js", "priority": "high", "demand_score": 85, "salary_impact": "+15%"},
                    {"name": "TypeScript", "priority": "high", "demand_score": 92, "salary_impact": "+20%"},
                    {"name": "Next.js", "priority": "high", "demand_score": 88, "salary_impact": "+16%"},
                    {"name": "Tailwind CSS", "priority": "medium", "demand_score": 82, "salary_impact": "+10%"},
                ],
                "backend": [
                    {"name": "Node.js", "priority": "high", "demand_score": 93, "salary_impact": "+18%"},
                    {"name": "Python", "priority": "high", "demand_score": 96, "salary_impact": "+22%"},
                    {"name": "Django", "priority": "medium", "demand_score": 80, "salary_impact": "+15%"},
                    {"name": "FastAPI", "priority": "medium", "demand_score": 78, "salary_impact": "+14%"},
                    {"name": "GraphQL", "priority": "medium", "demand_score": 75, "salary_impact": "+12%"},
                ],
                "devops": [
                    {"name": "Docker", "priority": "high", "demand_score": 94, "salary_impact": "+20%"},
                    {"name": "Kubernetes", "priority": "high", "demand_score": 90, "salary_impact": "+25%"},
                    {"name": "AWS", "priority": "high", "demand_score": 92, "salary_impact": "+22%"},
                    {"name": "Terraform", "priority": "high", "demand_score": 85, "salary_impact": "+18%"},
                    {"name": "CI/CD", "priority": "high", "demand_score": 91, "salary_impact": "+17%"},
                ],
                "database": [
                    {"name": "PostgreSQL", "priority": "high", "demand_score": 90, "salary_impact": "+15%"},
                    {"name": "MongoDB", "priority": "high", "demand_score": 85, "salary_impact": "+11%"},
                    {"name": "Redis", "priority": "medium", "demand_score": 78, "salary_impact": "+10%"},
                    {"name": "MySQL", "priority": "medium", "demand_score": 82, "salary_impact": "+9%"},
                ]
            },
            "marketing": {
                "digital_marketing": [
                    {"name": "Google Ads", "priority": "high", "demand_score": 90, "salary_impact": "+18%"},
                    {"name": "Meta Ads", "priority": "high", "demand_score": 88, "salary_impact": "+17%"},
                    {"name": "SEO", "priority": "high", "demand_score": 92, "salary_impact": "+16%"},
                    {"name": "Google Analytics", "priority": "high", "demand_score": 95, "salary_impact": "+12%"},
                ]
            },
            "soft_skills": [
                {"name": "Lideran√ßa", "priority": "high", "demand_score": 98, "salary_impact": "+25%"},
                {"name": "Comunica√ß√£o", "priority": "high", "demand_score": 99, "salary_impact": "+15%"},
                {"name": "Trabalho em Equipa", "priority": "high", "demand_score": 97, "salary_impact": "+12%"},
                {"name": "Resolu√ß√£o de Problemas", "priority": "high", "demand_score": 96, "salary_impact": "+18%"},
            ]
        }
        
        return database
    
    def generate_ats_keywords(self) -> Dict:
        """Gera keywords ATS por √°rea profissional"""
        print("üîë Gerando keywords ATS...")
        
        keywords = {
            "technology": {
                "must_have": ["desenvolveu", "implementou", "arquitetou", "otimizou", "escalou"],
                "strong": ["liderou", "geri", "mentorizou", "aumentou", "reduziu"],
                "metrics": ["% de melhoria", "utilizadores", "transa√ß√µes", "uptime"]
            },
            "marketing": {
                "must_have": ["executou", "otimizou", "analisou", "aumentou", "geriu"],
                "strong": ["lan√ßou", "desenvolveu", "coordenou", "maximizou"],
                "metrics": ["ROI", "convers√£o", "engagement", "reach", "impress√µes"]
            }
        }
        
        return keywords
    
    def save_all_datasets(self):
        """Salva todos os datasets"""
        print("\nüöÄ Iniciando gera√ß√£o de datasets...")
        print("="*60)
        
        # 1. Text Improvement
        text_data = self.generate_text_improvement_dataset()
        
        # Organizar por sec√ß√£o
        organized_data = {
            "metadata": {
                "version": "1.0.0",
                "created_at": datetime.now().isoformat(),
                "total_examples": len(text_data),
                "description": "Dataset processado para melhoria de texto em CVs"
            },
            "by_section": {
                "experience": [item for item in text_data if item["section"] == "experience"],
                "summary": [item for item in text_data if item["section"] == "summary"],
                "education": [item for item in text_data if item["section"] == "education"],
                "skills": [item for item in text_data if item["section"] == "skills"]
            }
        }
        
        with open(self.output_dir / "text_improvement.json", "w", encoding="utf-8") as f:
            json.dump(organized_data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ text_improvement.json: {len(text_data)} exemplos")
        
        # 2. Skills Database
        skills_data = self.generate_skills_database()
        skills_with_metadata = {
            "metadata": {
                "version": "1.0.0",
                "created_at": datetime.now().isoformat(),
                "description": "Base de dados de skills por √°rea profissional"
            },
            **skills_data
        }
        
        with open(self.output_dir / "skills_by_area.json", "w", encoding="utf-8") as f:
            json.dump(skills_with_metadata, f, ensure_ascii=False, indent=2)
        
        total_skills = sum(
            len(v) if isinstance(v, list) else sum(len(vv) for vv in v.values() if isinstance(vv, list))
            for k, v in skills_data.items()
        )
        print(f"‚úÖ skills_by_area.json: {total_skills} skills")
        
        # 3. ATS Keywords
        ats_data = self.generate_ats_keywords()
        ats_with_metadata = {
            "metadata": {
                "version": "1.0.0",
                "created_at": datetime.now().isoformat(),
                "description": "Keywords ATS otimizadas por √°rea"
            },
            **ats_data
        }
        
        with open(self.output_dir / "ats_keywords.json", "w", encoding="utf-8") as f:
            json.dump(ats_with_metadata, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ ats_keywords.json: {len(ats_data)} categorias")
        
        print("\n" + "="*60)
        print("‚ú® Datasets gerados com sucesso!")
        print(f"üìÅ Localiza√ß√£o: {self.output_dir.absolute()}")
        print("\nüí° Pr√≥ximo passo: python scripts/export_to_backend.py")

if __name__ == "__main__":
    generator = CVDatasetGenerator()
    generator.save_all_datasets()